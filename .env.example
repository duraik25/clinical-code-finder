# LLM Provider Configuration
#LLM_PROVIDER=ollama  # Options: ollama, openai
LLM_PROVIDER=openai  # Options: ollama, openai

# Ollama Settings (for local development)
OLLAMA_BASE_URL=http://localhost:11434
#OLLAMA_MODEL=llama2  # or mistral, codellama, etc.
OLLAMA_MODEL=gpt-oss:120b-cloud  # or mistral, codellama, etc.
#OLLAMA_MODEL=mistral  # or mistral, codellama, etc.

# OpenAI Settings (for production/testing)
OPENAI_API_KEY=<Add your opnai key here>
#OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o
#OPENAI_MODEL=gpt-3.5-turbo

# Shared LLM Settings
LLM_TEMPERATURE=0

# API Settings
API_TIMEOUT=30
MAX_RESULTS_PER_SYSTEM=10

# Agent Tuning
RELEVANCE_THRESHOLD=0.5
MAX_SECONDARY_SYSTEMS=3

# Logging
LOG_LEVEL=INFO
